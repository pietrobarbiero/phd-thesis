\chapter{Concept Quality} \label{chapter:metrics}
% \textbf{Research: completed. Status: drafted. Difficulty: low. Priority: low.}

% \textit{In this chapter I will discuss how to measure the quality of concept representations. In particular I will focus on my contribution in inventing the niche impurity score~\citep{zarlenga2021quality} which generalizes concept completeness~\citep{yeh2020completeness} to concept subsets. I will demonstrate how this metric is computationally efficient and does not require concept labels thus making it applicable in real-world supervised and unsupervised scenarios. I will conclude the chapter with experiments showing how the niche impurity score can be used in practice to evaluate the robustness of concept representations generated by state-of-the-art supervised and unsupervised concept learning methods.}

\textbf{Motivation---} Very few metrics available to assess concept quality. Hard to understand whether to trust concept-based models explanations based on learnt concepts.

\textbf{Solution---} Two new metrics to assess concept quality and robustness.

The \textbf{key innovation} consists in generalizing existing metrics to subset of concepts (niching) and to concept embeddings (alignment).

\section{Concept completeness}


\section{Concept niches and concept impurity}
\begin{definition}[Concept nicher] \label{def:nicher}
Given a set of concept representations $\hat{C} \subseteq \mathbb{R}^{d \times k}$, we define a concept nicher as a function $\nu: \{1, \cdots k\} \times \{1, \cdots k\} \mapsto [0, 1]$ that returns $\nu(i, j) \approx 1$ if the $i$-th concept $\mathbf{\hat{c}}_{(:, i)}$ is entangled with the $j$-th ground truth concept $c_j$, and $\nu(i, j) \approx 0$ otherwise.
\end{definition}

Our definition above can be instantiated in various ways, depending on how entanglement is measured. In favour of efficiency, we measure entanglement using absolute Pearson correlation $\rho$, as this measure can efficiently discover (a linear form of) association between variables~\cite{altman2015points}. We call this instantiation  \emph{concept-correlation nicher} (CCorrN) and define it as
$\text{CCorrN}(i, j) := \big| \rho\big(\{\mathbf{\hat{c}}^{(l)}_{(:, i)}\}_{l=1}^N, \{c^{(l)}_j\}_{l=1}^N\big) \big|$.

% The above definition is affected by how entanglement is defined. One efficient way of measuring the entanglement is to use the absolute Pearson correlation, denoted as $\rho$. We call such an instantiation a \emph{concept-correlation nicher} (CCorrN) and define it as:
% \[
%     \text{CCorrN}(i, j) := \big| \rho\big(\{\mathbf{\hat{c}}^{(l)}_{(:, i)}\}_{l=1}^N, \{\mathbf{\hat{c}}^{(l)}_j\}_{l=1}^N\big) \big|
% \]
If $\mathbf{\hat{c}}_{(:, i)}$ is not a scalar representation (i.e., $d > 1$), then for simplicity we use the maximum absolute correlation coefficient between all entries in $\mathbf{\hat{c}}_{(:, i)}$, and the target concept label $c_j$ as a representative correlation coefficient for the entire representation $\mathbf{\hat{c}}_{(:, i)}$. We then define a concept niche as: 
\begin{definition}[Concept niche]
The concept niche $N_j(\nu, \beta)$ for target concept $j$, determined by concept nicher $\nu(\cdot, \cdot)$ and threshold $\beta \in [0,1]$, is defined as $N_j(\nu, \beta) := \big\{i \ \ | \ \ i \in \{1, \cdots, k\} \text{ and } \nu(i, j) > \beta \big\}$.
\end{definition}

From this, the Niche Impurity (NI) measures the predictive capacity of the complement of concept niche $N_i(\nu, \beta)$, referred to as $\neg N_i(\nu, \beta) := \{1, \cdots, k\} \; \backslash \; N_i(\nu, \beta)$, for the $i$-th ground truth concept:
%Given the complement of concept niche $N_i(\nu, \beta)$, which we refer to as $\neg N_i(\nu, \beta) := \{1, \cdots, k\} \; \backslash \; N_j(\nu, \beta)$, the Niche Impurity (NI) measures its predictive capacity for the $i$-th ground truth concept.

\begin{definition}[Niche Impurity (NI)] \label{def:niche_impurity}
Given a classifier $f: \hat{C} \mapsto C$, concept nicher $\nu$, threshold $\beta \in [0, 1]$, and labeled concept representations $\{(\mathbf{\hat{c}}^{(l)}, \mathbf{c}^{(l)})\}_{l = 1}^n$, the Niche Impurity of the $i$-th output of $f(\cdot)$ is defined as $\text{NI}_i(f, \nu, \beta) := \text{AUC} \big( \{( f|_{\neg N_i(\nu, \beta)} \big( \mathbf{\hat{c}}^{(l)}_{(:, \neg N_i(\nu, \beta))} \big), c^{(l)}_i) \}_{l=1}^n \big)$, where $f|_{\neg N_j(\nu, \beta)}$
% : \hat{C} \mapsto C$
is the classifier resulting from masking all entries in $\neg N_j(\nu, \beta)$ when feeding $f$ with concept representations. 
\end{definition}

Although $f$ can be any classifier, in our experiments we use a ReLU MLP with hidden layer sizes $\{ 20, 20 \}$.
Intuitively, a NI of $1/2$ (random AUC of niche complement) indicates that the concepts inside the niche $N_i(\nu)$ are the only concepts predictive of the $i$-th concept, that is, concepts outside the niche do not hold any predictive information of the $i$-th concept.
% In contrast, a NI of $1$ suggests that concepts outside the nice $N_i(\nu)$ are still fully predictive of concept $i$.
Finally, the \textit{Niche Impurity Score} metric measures how much information apparently disentangled concepts
% (target concepts and their niche complements)
are actually sharing:

\begin{definition}[Niche Impurity Score (NIS)] \label{def:niche_impurity_score}
Given a classifier $f: \hat{C} \mapsto C$ and concept nicher $\nu$, the niche impurity score $\text{NIS}(f,\nu) \in [0,1]$ is defined as the summation of niche impurities across all concepts for different values of $\beta$: $\text{NIS}(f,\nu) := \int_{0}^{1} (\sum_{i=1}^{k} \text{NI}_i(f, \nu, \beta)/k) d\beta$.
\end{definition}

In practice, we estimate this integral using the trapezoid method with values in $\beta \in \{ 0.0, 0.05, \cdots, 1\}$. For efficiency, we parameterise $f$ as an MLP,
% one can very efficiently compute the NI for different concepts and values of $\beta$,
leading to a tractable impurity metric which easily scales as the number of concepts $k$ increases. Intuitively, a NIS of $1$ means that all the information to perfectly predict each ground truth concept is spread on many different and disentangled concept representations. In contrast, a NIS around $1/2$ (random AUC) indicates that no concept can be predicted by any concept representation subset.
% Intuitively, a NIS score of $1$ conveys perfect purity and means that the set of learnt concepts can be divided into disentangled sets, each of which is related to predicting a single ground truth concept, while the NIS score around $1/2$ conveys maximum impurity and indicates that information related to each ground truth concept is scattered across all assumed disentangled sets of learnt concepts.

\section{Concept alignment}
The Concept Alignment Score (CAS) aims to measure how much learnt concept representations can be trusted as faithful representations of their ground truth concept labels. Intuitively, CAS generalises concept accuracy by considering the predictions' homogeneity within groups of similar samples. More specifically, CAS applies a clustering algorithm $\kappa$ to find $\rho > 2$ clusters, assigning to each sample $\mathbf{x}^{(j)}$, for each concept $c_i$, a cluster label $\pi_i^{(j)} \in \{1, \cdots, \rho\}$, using the concept representation $\hat{\textbf{c}}_i$. Given $N$ test samples, the homogeneity score $h(\cdot)$~\citep{rosenberg2007v} then computes the conditional entropy $H$ of ground truth labels $C_i = \{c_i^{(j)}\}_{j=1}^{N}$ w.r.t. cluster labels $\Pi_i = \{\pi_i^{(j)}\}_{j=1}^{N}$, i.e., $h = 1$ when $H(C_i,\Pi_i)=0$ and $h = 1 - H(C_i, \Pi_i)/H(C_i)$ otherwise. The higher the homogeneity, the more a learnt concept representation is ``aligned'' with its labels, and can thus be trusted as a faithful representation. CAS averages homogeneity scores over all concepts, providing a normalised score $\text{CAS} \in [0,1]$:
\begin{equation}
    \text{CAS}(\mathbf{\hat{c}}_1, \cdots, \mathbf{\hat{c}}_k) \triangleq \frac{1}{N - 2}\sum_{p=2}^N \Bigg(\frac{1}{k} \sum_{i=1}^k h(c_i, \kappa_p(\hat{\textbf{c}}_i)) \Bigg)
    % \text{CAS}(\mathbf{\hat{c}}_1, \cdots, \mathbf{\hat{c}}_k) := \frac{1}{k(N-2)} \sum_{p=2}^N \sum_{i=1}^k h(c_i, \kappa(\ha  t{\textbf{c}}_i, p)))
\end{equation}
% Notice how when the number of clusters $p$ equals the number of samples, CAS and concept accuracy are identical.
% The concept alignment score is therefore maximal (i.e., $\text{CAS} = 1$) when all clusters contain only data points which are members of a single concept class (i.e., for all samples within a cluster, the label of any concept $i$ is either always $c_i = True$ or always $c_i = False$). 
To tractably compute CAS in practice, we sum homogeneity scores by varying $p$ across $p \in \{2, 2 + \delta, 2 + 2 \delta, \cdots, N\}$ for some $\delta > 1$ (details in Appendix). Furthermore, we use k-Medoids~\citep{kaufman1990partitioning} for cluster discovery, similarly to~\citet{ghorbani2019interpretation} and~\citet{magister2021gcexplainer}, and use concept logits when computing the CAS for Boolean and Fuzzy CBMs. For Hybrid CBMs, we use $\hat{\mathbf{c}}_i \triangleq [\hat{\mathbf{c}}_{[k:k + \gamma]}, \hat{\mathbf{c}}_{[i:(i + 1)]}]^T$ as the concept representation for $c_i$ (i.e., the extra capacity is a shared embedding across all concepts).
% Cluster and concept labels are matched by homogeneity score.
% and use a simple majority class count for labeling a cluster.

\section{Trade-offs in concept learning}
\begin{itemize}
    \item Accuracy vs. scalability/noise
    \item Accuracy vs. explainability
    \item Accuracy vs. interpretability
\end{itemize}


\section*{Papers}
\nobibliography*
\begin{itemize}
    \item \bibentry{zarlenga2021quality}
\end{itemize}
